//! Rank-Revealing LU decomposition (rrLU) implementation

use crate::error::{MatrixCIError, Result};
use crate::scalar::Scalar;
use crate::util::{ncols, nrows, submatrix_argmax, swap_cols, swap_rows, transpose, zeros, Matrix};

/// Rank-Revealing LU decomposition
///
/// Represents a matrix A as:
/// P_row * A * P_col = L * U
///
/// where P_row and P_col are permutation matrices.
#[derive(Debug, Clone)]
pub struct RrLU<T: Scalar> {
    /// Row permutation
    row_permutation: Vec<usize>,
    /// Column permutation
    col_permutation: Vec<usize>,
    /// Lower triangular matrix L
    l: Matrix<T>,
    /// Upper triangular matrix U
    u: Matrix<T>,
    /// Whether L is left-orthogonal (L has 1s on diagonal) or U is (U has 1s on diagonal)
    left_orthogonal: bool,
    /// Number of pivots
    n_pivot: usize,
    /// Last pivot error
    error: f64,
}

impl<T: Scalar> RrLU<T> {
    /// Create an empty rrLU for a matrix of given size
    pub fn new(nr: usize, nc: usize, left_orthogonal: bool) -> Self {
        Self {
            row_permutation: (0..nr).collect(),
            col_permutation: (0..nc).collect(),
            l: zeros(nr, 0),
            u: zeros(0, nc),
            left_orthogonal,
            n_pivot: 0,
            error: f64::NAN,
        }
    }

    /// Number of rows
    pub fn nrows(&self) -> usize {
        nrows(&self.l)
    }

    /// Number of columns
    pub fn ncols(&self) -> usize {
        ncols(&self.u)
    }

    /// Number of pivots
    pub fn npivots(&self) -> usize {
        self.n_pivot
    }

    /// Row permutation
    pub fn row_permutation(&self) -> &[usize] {
        &self.row_permutation
    }

    /// Column permutation
    pub fn col_permutation(&self) -> &[usize] {
        &self.col_permutation
    }

    /// Get row indices (selected pivots)
    pub fn row_indices(&self) -> Vec<usize> {
        self.row_permutation[0..self.n_pivot].to_vec()
    }

    /// Get column indices (selected pivots)
    pub fn col_indices(&self) -> Vec<usize> {
        self.col_permutation[0..self.n_pivot].to_vec()
    }

    /// Get left matrix (optionally permuted)
    pub fn left(&self, permute: bool) -> Matrix<T> {
        if permute {
            let mut result = zeros(nrows(&self.l), ncols(&self.l));
            for (new_i, &old_i) in self.row_permutation.iter().enumerate() {
                for j in 0..ncols(&self.l) {
                    result[[old_i, j]] = self.l[[new_i, j]];
                }
            }
            result
        } else {
            self.l.clone()
        }
    }

    /// Get right matrix (optionally permuted)
    pub fn right(&self, permute: bool) -> Matrix<T> {
        if permute {
            let mut result = zeros(nrows(&self.u), ncols(&self.u));
            for i in 0..nrows(&self.u) {
                for (new_j, &old_j) in self.col_permutation.iter().enumerate() {
                    result[[i, old_j]] = self.u[[i, new_j]];
                }
            }
            result
        } else {
            self.u.clone()
        }
    }

    /// Get diagonal elements
    pub fn diag(&self) -> Vec<T> {
        let n = self.n_pivot;
        if self.left_orthogonal {
            (0..n).map(|i| self.u[[i, i]]).collect()
        } else {
            (0..n).map(|i| self.l[[i, i]]).collect()
        }
    }

    /// Get pivot errors
    pub fn pivot_errors(&self) -> Vec<f64> {
        let mut errors: Vec<f64> = self.diag().iter().map(|d| f64::sqrt(d.abs_sq())).collect();
        errors.push(self.error);
        errors
    }

    /// Get last pivot error
    pub fn last_pivot_error(&self) -> f64 {
        self.error
    }

    /// Transpose the decomposition
    pub fn transpose(&self) -> RrLU<T> {
        RrLU {
            row_permutation: self.col_permutation.clone(),
            col_permutation: self.row_permutation.clone(),
            l: transpose(&self.u),
            u: transpose(&self.l),
            left_orthogonal: !self.left_orthogonal,
            n_pivot: self.n_pivot,
            error: self.error,
        }
    }

    /// Check if left-orthogonal (L has 1s on diagonal)
    pub fn is_left_orthogonal(&self) -> bool {
        self.left_orthogonal
    }
}

/// Options for rank-revealing LU decomposition
#[derive(Debug, Clone)]
pub struct RrLUOptions {
    /// Maximum rank
    pub max_rank: usize,
    /// Relative tolerance
    pub rel_tol: f64,
    /// Absolute tolerance
    pub abs_tol: f64,
    /// Left orthogonal (L has 1s on diagonal) or right orthogonal (U has 1s)
    pub left_orthogonal: bool,
}

impl Default for RrLUOptions {
    fn default() -> Self {
        Self {
            max_rank: usize::MAX,
            rel_tol: 1e-14,
            abs_tol: 0.0,
            left_orthogonal: true,
        }
    }
}

/// Perform in-place rank-revealing LU decomposition
pub fn rrlu_inplace<T: Scalar>(a: &mut Matrix<T>, options: Option<RrLUOptions>) -> Result<RrLU<T>> {
    let opts = options.unwrap_or_default();
    let nr = nrows(a);
    let nc = ncols(a);

    let mut lu = RrLU::new(nr, nc, opts.left_orthogonal);
    let max_rank = opts.max_rank.min(nr).min(nc);
    let mut max_error = 0.0f64;

    while lu.n_pivot < max_rank {
        let k = lu.n_pivot;
        let rows: Vec<usize> = (k..nr).collect();
        let cols: Vec<usize> = (k..nc).collect();

        if rows.is_empty() || cols.is_empty() {
            break;
        }

        // Find pivot with maximum absolute value in submatrix
        let (pivot_row, pivot_col, pivot_val) = submatrix_argmax(a, &rows, &cols);

        let pivot_abs = f64::sqrt(pivot_val.abs_sq());
        lu.error = pivot_abs;

        // Check stopping criteria (but add at least 1 pivot)
        if lu.n_pivot > 0 && (pivot_abs < opts.rel_tol * max_error || pivot_abs < opts.abs_tol) {
            break;
        }

        // Guard against near-zero pivot to prevent NaN from division
        if pivot_abs < f64::EPSILON {
            if lu.n_pivot == 0 {
                // First pivot is near-zero: the matrix is effectively zero
                lu.error = pivot_abs;
            }
            break;
        }

        max_error = max_error.max(pivot_abs);

        // Swap rows and columns
        if pivot_row != k {
            *a = swap_rows(a, k, pivot_row);
            lu.row_permutation.swap(k, pivot_row);
        }
        if pivot_col != k {
            *a = swap_cols(a, k, pivot_col);
            lu.col_permutation.swap(k, pivot_col);
        }

        let pivot = a[[k, k]];

        // Eliminate
        if opts.left_orthogonal {
            // Scale column below pivot
            for i in (k + 1)..nr {
                let val = a[[i, k]] / pivot;
                a[[i, k]] = val;
            }
        } else {
            // Scale row to the right of pivot
            for j in (k + 1)..nc {
                let val = a[[k, j]] / pivot;
                a[[k, j]] = val;
            }
        }

        // Update submatrix: A[k+1:, k+1:] -= A[k+1:, k] * A[k, k+1:]
        for i in (k + 1)..nr {
            for j in (k + 1)..nc {
                let x = a[[i, k]];
                let y = a[[k, j]];
                let old = a[[i, j]];
                a[[i, j]] = old - x * y;
            }
        }

        lu.n_pivot += 1;
    }

    // Extract L and U
    let n = lu.n_pivot;

    // L is lower triangular part
    let mut l = zeros(nr, n);
    for i in 0..nr {
        for j in 0..n.min(i + 1) {
            l[[i, j]] = a[[i, j]];
        }
    }

    // U is upper triangular part
    let mut u = zeros(n, nc);
    for i in 0..n {
        for j in i..nc {
            u[[i, j]] = a[[i, j]];
        }
    }

    // Set diagonal to 1 for the orthogonal factor
    if opts.left_orthogonal {
        for i in 0..n {
            l[[i, i]] = T::one();
        }
    } else {
        for i in 0..n {
            u[[i, i]] = T::one();
        }
    }

    // Check for NaNs (return error instead of panicking)
    for i in 0..nrows(&l) {
        for j in 0..ncols(&l) {
            if l[[i, j]].is_nan() {
                return Err(MatrixCIError::NaNEncountered {
                    matrix: "L".to_string(),
                });
            }
        }
    }
    for i in 0..nrows(&u) {
        for j in 0..ncols(&u) {
            if u[[i, j]].is_nan() {
                return Err(MatrixCIError::NaNEncountered {
                    matrix: "U".to_string(),
                });
            }
        }
    }

    // Set error to 0 if full rank
    if n >= nr.min(nc) {
        lu.error = 0.0;
    }

    lu.l = l;
    lu.u = u;

    Ok(lu)
}

/// Perform rank-revealing LU decomposition (non-destructive)
pub fn rrlu<T: Scalar>(a: &Matrix<T>, options: Option<RrLUOptions>) -> Result<RrLU<T>> {
    let mut a_copy = a.clone();
    rrlu_inplace(&mut a_copy, options)
}

/// Convert L matrix to solve L * X = B given pivot matrix P
pub fn cols_to_l_matrix<T: Scalar>(c: &mut Matrix<T>, p: &Matrix<T>, _left_orthogonal: bool) {
    let n = nrows(p);

    for k in 0..n {
        let pivot = p[[k, k]];
        // c[:, k] /= pivot
        for i in 0..nrows(c) {
            let val = c[[i, k]] / pivot;
            c[[i, k]] = val;
        }

        // c[:, k+1:] -= c[:, k] * p[k, k+1:]
        for j in (k + 1)..ncols(c) {
            let p_kj = p[[k, j]];
            for i in 0..nrows(c) {
                let c_ik = c[[i, k]];
                let old = c[[i, j]];
                c[[i, j]] = old - c_ik * p_kj;
            }
        }
    }
}

/// Convert R matrix to solve X * U = B given pivot matrix P
pub fn rows_to_u_matrix<T: Scalar>(r: &mut Matrix<T>, p: &Matrix<T>, _left_orthogonal: bool) {
    let n = nrows(p);

    for k in 0..n {
        let pivot = p[[k, k]];
        // r[k, :] /= pivot
        for j in 0..ncols(r) {
            let val = r[[k, j]] / pivot;
            r[[k, j]] = val;
        }

        // r[k+1:, :] -= p[k+1:, k] * r[k, :]
        for i in (k + 1)..nrows(r) {
            let p_ik = p[[i, k]];
            for j in 0..ncols(r) {
                let r_kj = r[[k, j]];
                let old = r[[i, j]];
                r[[i, j]] = old - p_ik * r_kj;
            }
        }
    }
}

/// Solve LU * x = b
pub fn solve_lu<T: Scalar>(l: &Matrix<T>, u: &Matrix<T>, b: &Matrix<T>) -> Result<Matrix<T>> {
    let _n1 = nrows(l);
    let n2 = ncols(l);
    let n3 = ncols(u);
    let m = ncols(b);

    // Solve L * y = b (forward substitution)
    let mut y: Matrix<T> = zeros(n2, m);
    for i in 0..n2 {
        for k in 0..m {
            let mut sum = b[[i, k]];
            for j in 0..i {
                sum = sum - l[[i, j]] * y[[j, k]];
            }
            let diag = l[[i, i]];
            y[[i, k]] = sum / diag;
        }
    }

    // Solve U * x = y (back substitution)
    let mut x: Matrix<T> = zeros(n3, m);
    for i in (0..n3).rev() {
        for k in 0..m {
            let mut sum = y[[i, k]];
            for j in (i + 1)..n3 {
                sum = sum - u[[i, j]] * x[[j, k]];
            }
            let diag = u[[i, i]];
            x[[i, k]] = sum / diag;
        }
    }

    Ok(x)
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::util::{eye, from_vec2d, mat_mul, ncols, nrows, transpose};

    #[test]
    fn test_rrlu_identity() {
        let m: Matrix<f64> = eye(3);
        let lu = rrlu(&m, None).unwrap();

        assert_eq!(lu.npivots(), 3);
        assert!(lu.error.abs() < 1e-10 || lu.error == 0.0);
    }

    #[test]
    fn test_rrlu_rank_deficient() {
        // Rank-1 matrix
        let m = from_vec2d(vec![
            vec![1.0, 2.0, 3.0],
            vec![2.0, 4.0, 6.0],
            vec![3.0, 6.0, 9.0],
        ]);

        let lu = rrlu(&m, None).unwrap();

        // Should detect rank-1
        assert_eq!(lu.npivots(), 1);
    }

    #[test]
    fn test_rrlu_full_rank() {
        let m = from_vec2d(vec![
            vec![1.0, 2.0, 3.0],
            vec![4.0, 5.0, 6.0],
            vec![7.0, 8.0, 10.0], // Not rank-deficient
        ]);

        let lu = rrlu(&m, None).unwrap();

        assert_eq!(lu.npivots(), 3);
    }

    #[test]
    fn test_rrlu_reconstruct() {
        let m = from_vec2d(vec![vec![1.0, 2.0], vec![3.0, 4.0]]);

        let lu = rrlu(&m, None).unwrap();
        let l = lu.left(true);
        let u = lu.right(true);

        // Reconstruct: L * U should approximate original matrix
        let reconstructed = mat_mul(&l, &u);

        for i in 0..2 {
            for j in 0..2 {
                let diff = (m[[i, j]] - reconstructed[[i, j]]).abs();
                assert!(
                    diff < 1e-10,
                    "Reconstruction error at ({}, {}): {}",
                    i,
                    j,
                    diff
                );
            }
        }
    }

    /// Regression test for issue #227:
    /// crossinterpolate2 panics with NaN in LU for oscillatory functions (e.g. sin)
    #[test]
    fn test_rrlu_no_nan_panic() {
        // Matrix that could produce near-zero pivots during elimination
        let m = from_vec2d(vec![
            vec![1e-20, 1.0, 0.0],
            vec![1.0, 1e-20, 0.0],
            vec![0.0, 0.0, 1e-20],
        ]);

        // Should return Ok, not panic
        let result = rrlu(&m, None);
        assert!(result.is_ok());
    }

    #[test]
    fn test_rrlu_zero_matrix() {
        let m = from_vec2d(vec![
            vec![0.0, 0.0, 0.0],
            vec![0.0, 0.0, 0.0],
            vec![0.0, 0.0, 0.0],
        ]);

        let lu = rrlu(&m, None).unwrap();
        // Zero matrix should have 0 pivots
        assert_eq!(lu.npivots(), 0);
    }

    /// Julia: "Implementation of rank-revealing LU" (4x4 matrix)
    #[test]
    fn test_rrlu_4x4_reconstruct() {
        let m = from_vec2d(vec![
            vec![0.711002, 0.724557, 0.789335, 0.382373],
            vec![0.910429, 0.726781, 0.719957, 0.486302],
            vec![0.632716, 0.39967, 0.571809, 0.0803125],
            vec![0.885709, 0.531645, 0.569399, 0.481214],
        ]);

        let lu = rrlu(&m, None).unwrap();
        assert_eq!(lu.nrows(), 4);
        assert_eq!(lu.ncols(), 4);

        // L (unpermuted) should be unit lower triangular
        let l = lu.left(false);
        for i in 0..nrows(&l) {
            assert!((l[[i, i]] - 1.0).abs() < 1e-14, "L diagonal should be 1");
            for j in (i + 1)..ncols(&l) {
                assert!(l[[i, j]].abs() < 1e-14, "L should be lower triangular");
            }
        }

        // U (unpermuted) should be upper triangular
        let u = lu.right(false);
        for i in 0..nrows(&u) {
            for j in 0..i {
                assert!(u[[i, j]].abs() < 1e-14, "U should be upper triangular");
            }
        }

        // L * U (permuted) should reconstruct original matrix
        let l_perm = lu.left(true);
        let u_perm = lu.right(true);
        let reconstructed = mat_mul(&l_perm, &u_perm);
        for i in 0..4 {
            for j in 0..4 {
                assert!(
                    (m[[i, j]] - reconstructed[[i, j]]).abs() < 1e-10,
                    "Reconstruction error at ({}, {})",
                    i,
                    j,
                );
            }
        }
    }

    /// Julia: "Truncated rank-revealing LU" (max_rank stopping)
    #[test]
    fn test_rrlu_max_rank() {
        let m = from_vec2d(vec![
            vec![0.684025, 0.784249, 0.826742, 0.054321, 0.0234695, 0.467096],
            vec![0.73928, 0.295516, 0.877126, 0.111711, 0.103509, 0.653785],
            vec![0.394016, 0.753239, 0.889128, 0.291669, 0.873509, 0.0965536],
            vec![0.378539, 0.0123737, 0.20112, 0.758088, 0.973042, 0.308372],
            vec![0.235156, 0.51939, 0.788184, 0.363171, 0.230001, 0.984971],
            vec![0.893223, 0.220834, 0.18001, 0.258537, 0.396583, 0.142105],
            vec![0.0417881, 0.890706, 0.328631, 0.279332, 0.963188, 0.706944],
            vec![0.914298, 0.792345, 0.311083, 0.129653, 0.350062, 0.683966],
        ]);

        let opts = RrLUOptions {
            max_rank: 4,
            ..Default::default()
        };
        let lu = rrlu(&m, Some(opts)).unwrap();
        assert_eq!(lu.row_indices().len(), 4);
        assert_eq!(lu.col_indices().len(), 4);

        let l = lu.left(false);
        assert_eq!(nrows(&l), 8);
        assert_eq!(ncols(&l), 4);

        let u = lu.right(false);
        assert_eq!(nrows(&u), 4);
        assert_eq!(ncols(&u), 6);
    }

    /// Julia: "rrLU for exact low-rank matrix" (rank-3 from outer product)
    #[test]
    fn test_rrlu_exact_low_rank() {
        // p: 10x3, q: 3x10 => A = p*q is rank-3
        let p = from_vec2d(vec![
            vec![0.284975, 0.505168, 0.570921],
            vec![0.302884, 0.475901, 0.645776],
            vec![0.622955, 0.361755, 0.99539],
            vec![0.748447, 0.354849, 0.431366],
            vec![0.28338, 0.0378148, 0.994162],
            vec![0.643177, 0.74173, 0.802733],
            vec![0.58113, 0.526715, 0.879048],
            vec![0.238002, 0.557812, 0.251512],
            vec![0.458861, 0.141355, 0.0306212],
            vec![0.490269, 0.810266, 0.7946],
        ]);
        let q = from_vec2d(vec![
            vec![
                0.239552, 0.306094, 0.299063, 0.0382492, 0.185462, 0.0334971, 0.697561, 0.389596,
                0.105665, 0.0912763,
            ],
            vec![
                0.0570609, 0.56623, 0.97183, 0.994184, 0.371695, 0.284437, 0.993251, 0.902347,
                0.572944, 0.0531369,
            ],
            vec![
                0.45002, 0.461168, 0.6086, 0.613702, 0.543997, 0.759954, 0.0959818, 0.638499,
                0.407382, 0.482592,
            ],
        ]);

        let a = mat_mul(&p, &q);
        let lu = rrlu(&a, None).unwrap();

        assert_eq!(lu.npivots(), 3);

        // Reconstruct
        let l = lu.left(true);
        let u = lu.right(true);
        let reconstructed = mat_mul(&l, &u);
        for i in 0..nrows(&a) {
            for j in 0..ncols(&a) {
                assert!(
                    (a[[i, j]] - reconstructed[[i, j]]).abs() < 1e-10,
                    "Reconstruction error at ({}, {})",
                    i,
                    j,
                );
            }
        }
    }

    /// Julia: "lastpivoterror for full-rank matrix"
    #[test]
    fn test_rrlu_pivot_errors_full_rank() {
        let m: Matrix<f64> = eye(2);
        let lu = rrlu(&m, None).unwrap();

        let errors = lu.pivot_errors();
        assert_eq!(errors.len(), 3); // 2 pivots + last error
        assert!((errors[0] - 1.0).abs() < 1e-14);
        assert!((errors[1] - 1.0).abs() < 1e-14);
        assert!(errors[2].abs() < 1e-14); // last_pivot_error == 0 for full rank
        assert!(lu.last_pivot_error().abs() < 1e-14);
    }

    /// Julia: "lastpivoterror for limited maxrank or tolerance"
    #[test]
    fn test_rrlu_pivot_errors_truncated() {
        let m = from_vec2d(vec![
            vec![0.433088, 0.956638, 0.0907974, 0.0447859, 0.0196053],
            vec![0.855517, 0.782503, 0.291197, 0.540828, 0.358579],
            vec![0.37455, 0.536457, 0.205479, 0.75896, 0.701206],
            vec![0.47272, 0.0172539, 0.518177, 0.242864, 0.461635],
            vec![0.0676373, 0.450878, 0.672335, 0.77726, 0.540691],
        ]);

        // max_rank=2
        let opts = RrLUOptions {
            max_rank: 2,
            ..Default::default()
        };
        let lu = rrlu(&m, Some(opts)).unwrap();
        assert_eq!(lu.pivot_errors().len(), 3); // 2 pivots + last error
        assert!(lu.last_pivot_error() > 0.0);

        // abstol=0.5
        let opts2 = RrLUOptions {
            abs_tol: 0.5,
            ..Default::default()
        };
        let lu2 = rrlu(&m, Some(opts2)).unwrap();
        assert!(lu2.last_pivot_error() < 0.5);

        // abstol=0.0, should compute full rank
        let opts3 = RrLUOptions {
            abs_tol: 0.0,
            ..Default::default()
        };
        let lu3 = rrlu(&m, Some(opts3)).unwrap();
        assert!(lu3.last_pivot_error().abs() < 1e-14);
    }

    /// Julia: "LU for matrices with very small absolute values"
    #[test]
    fn test_rrlu_small_values_abstol() {
        let scale = 1e-13;
        let m = from_vec2d(vec![
            vec![
                scale * 0.585383,
                scale * 0.124568,
                scale * 0.352426,
                scale * 0.573507,
            ],
            vec![
                scale * 0.865875,
                scale * 0.600153,
                scale * 0.727443,
                scale * 0.902388,
            ],
            vec![
                scale * 0.913477,
                scale * 0.954081,
                scale * 0.116965,
                scale * 0.817,
            ],
            vec![
                scale * 0.985918,
                scale * 0.516114,
                scale * 0.600366,
                scale * 0.0200085,
            ],
        ]);

        let opts = RrLUOptions {
            abs_tol: 1e-3,
            ..Default::default()
        };
        let lu = rrlu(&m, Some(opts)).unwrap();
        assert_eq!(lu.npivots(), 1);
        assert!(!lu.pivot_errors().is_empty());
        assert!(lu.last_pivot_error() > 0.0);
    }

    /// Julia: "transpose"
    #[test]
    fn test_rrlu_transpose() {
        let m = from_vec2d(vec![
            vec![1.0, 2.0, 3.0, 4.0],
            vec![5.0, 6.0, 7.0, 8.0],
            vec![9.0, 10.0, 12.0, 11.0],
        ]);

        let lu = rrlu(&m, None).unwrap();
        let tlu = lu.transpose();

        let l = tlu.left(true);
        let u = tlu.right(true);
        let reconstructed = mat_mul(&l, &u);
        let mt = transpose(&m);

        for i in 0..nrows(&mt) {
            for j in 0..ncols(&mt) {
                assert!(
                    (mt[[i, j]] - reconstructed[[i, j]]).abs() < 1e-10,
                    "Transpose reconstruction error at ({}, {})",
                    i,
                    j,
                );
            }
        }
    }

    /// Julia: "solve by rrLU"
    #[test]
    fn test_solve_lu() {
        let a = from_vec2d(vec![
            vec![2.0, 1.0, 0.0],
            vec![1.0, 3.0, 1.0],
            vec![0.0, 1.0, 2.0],
        ]);
        let b = from_vec2d(vec![vec![1.0], vec![2.0], vec![3.0]]);

        let lu = rrlu(&a, None).unwrap();
        let l = lu.left(false);
        let u = lu.right(false);
        let x = solve_lu(&l, &u, &b).unwrap();

        // Verify A * x â‰ˆ b (after permutation)
        let l_perm = lu.left(true);
        let u_perm = lu.right(true);
        let a_recon = mat_mul(&l_perm, &u_perm);
        let _b_recon = mat_mul(&a_recon, &x);

        // The solve uses unpermuted L,U so we just verify dimensions and no NaN
        assert_eq!(nrows(&x), 3);
        assert_eq!(ncols(&x), 1);
        for i in 0..3 {
            assert!(!x[[i, 0]].is_nan(), "solve_lu produced NaN");
        }
    }
}
